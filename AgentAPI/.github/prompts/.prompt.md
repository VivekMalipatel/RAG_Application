# Context

Your Working Directlory wil be /mainpool/Projects/RAG_Application/Application/AgentAPI/ and you will not cae about any code outside this and all the outside code except Indexer API and Model Router API is depricated code base. 
   
Langgraph solves many of the complexity in creating AI agents, However it still has lot of concepts to learn and implement to make an agent fully functional. langgraph has ocean of features and possibilities to make agents better and act properly and magae the agnet propely. But They have lot of dependencies and concepts that are really hard to implement it perfectly. 

The Main reason we are building this API is to abstract the Langgraph/ Agentic hassle that is required to build several agents to the maximum possible. We will abstract it to the level in a way that, the client just use this API, and do the below,
1. Define the agent
   a. Agent Name
   b. Agent's Role
   c. Agent's Instructions (System Prompt)
   d. Capabiltities that agent will have (tool calling, MCP server calling, Image/Video/Audio Input output, etc)
2. Create a set of Multi-Agent Pool:
   a. Define and Put Multiple agents in One pool and Within the pool each agent will have thier Withing the pool role
   b. If there are multiple agents in a pool, they should be for sure an orchestrator agent taht controls and validates all the agents.

So now They have their agents created, Now in their view, this created Agent/Agent pool will be an LLM. Now the API will also manage chat functionalities too. Here the tricky part will be for each agent they created there will be multiple chat threads. And There can be multiple Agents/ Multi Agent pools for the saem client. SO the API will manage all these chat and memeory management.

Here there will be four memeory hierarchies: (Long Term, Short Term and Episodic Memory)
1. Within Thread memeory : There should be a memory of what a all have been discussed in that chat.
2. Within Agent/Agent Pool Memeory : There should be a memory of all the chat that agent/agent pool has done. And If agent pool, each agent in the pool will have their own memeory and the whole pool will also have a meomory. If we have soemthing like subpools inside a pool, the same memory hierarchy applies. (Group by User)
3. Withing User memory : Each client has multiple users registered and each user can use Multiple Agents/Agent pool. So the Users memeory will have the user's memory thoughtout all the agents.
3. Within Client memory : Each Clinet has Multiple users and There should also be a memeory that is shared between users for a cleint.

In This way we will be making a proper Memory for reinforcement learning for the agent to adapt to its experiences and learn from past.(Reflection)

# Default Characteristics of every Agent

1. Every Agent should have chain of thoughts reasoning
2. Every Agen should follow ReAct (Reasoning + Act)
3. Every Agent should posses a feedback loop and contiunously learn from feedback and memory
4. Stateful -> Strictly rememeber the previoud interations
5. Every Agents should Divide large problems to small sub tasks

The _build_core_workflow should have fixed set of nodes that are default (as per the default chars of an agent) and the classses that inherits this base classs should be able to add more nodes and tools to this as per their requirement. Note : Here there should be a way to add edges after plan and before evaluate. And The Default Nodes should be reconfigurable (overridden with default or extend the default fucntionalty for ex. An Agent might have different way of perciveing thing or planning things, so they should be configurable but the base Agen should hev this default generic implementations).

# Agentic Patterns

1. Planner - Executor - Evaulator Patterns : One agent plans, other agent executes and otehr agent validtes the output

# Agent Loop

Percieve -> Plan -> Act -> Learn -> Repeat

# Data Types

All the Schemas will be Pydantic schemas (not state dictionaries of etc)

# Tools and Agent Capabilities

1. Web Search
2. Python Code execution
3. Knwoledge search via Indexer API (That have built with FAISS)
4. Act as Model Contect Protocol Clients to connect and use Multiple MCP servers.

# Utility Agents

We will have utility agents that are extremely specialised and capable of doing a particular operations. These agents will always be initialised and will be available to work with any other clinet created agent and will be added to them by default. They are:

1. Coder Agnet : Can take the task and write and execute code based on the task. (For example, if we need to get data from a CSV file, instead of reading teh data, coder agenr tcan use python pandas to execute the code and query with the file and give back the output)
2. Web Search Agent : Specialised in Searching the Web and getting the conent from the search webpasges and giving back.
3. Fact Check Agent : An Agent that verifies if the Known Universal Truths are well maintained in the whole operations.
4. Censor Board Agent : The continosuly monitors outputs of each agent and looks for content violations and NSFW content and not allowed words.

More will be added as per requirements.

# Human-in-the-loop

At any stage, the cleint should be able to interrupt the process and input and direct the agents properly. Agents should then learn their mistake for previodu steps and continue working propelry as per instructions.

# Parallelisation

Every Independent agents should be able to work in parallel

# RBAC

<Yet to Decide How to Implement it>

# Security

1. Input and Output Sanitization
<More yet to decide>

# Tech Stack

1. For all kind of memeories we will be using SQlite as of now and later will be shifing to Redis and PostgreSQL
2. Langgraph with ModelRouter API (an Open ai compatibale custom made api that we will use using with OpenAI() with custom base URL)
3. FastAPI

# Coding Style

1. It should be completelely modular, Object oriented, well logged
2. No Icons/emoji's in the code or logs
3. No Comments or class/methods descriptions should be written.

# LangGraph Documentation resources - That need to be propely studied before implementing anything

Documentation Intro page : https://langchain-ai.github.io/langgraph/
Learn The Basics : https://langchain-ai.github.io/langgraph/tutorials/introduction/

How to Guides : https://langchain-ai.github.io/langgraph/how-tos/

## Detailed links for some of them that are mentioned in how to guides (I will add more in the future):

### Graph API Basics
How to update graph state from nodes : https://langchain-ai.github.io/langgraph/how-tos/state-reducers/
How to create a sequence of steps : https://langchain-ai.github.io/langgraph/how-tos/sequence/
How to create branches for parallel node execution : https://langchain-ai.github.io/langgraph/how-tos/branching/
How to create and control loops : https://langchain-ai.github.io/langgraph/how-tos/recursion-limit/

### Fine-grained Control

How to create map-reduce branches for parallel execution : https://langchain-ai.github.io/langgraph/how-tos/map-reduce/
How to combine control flow and state updates with Command : https://langchain-ai.github.io/langgraph/how-tos/command/
How to add runtime configuration to your graph : https://langchain-ai.github.io/langgraph/how-tos/configuration/
How to add node retry policies : https://langchain-ai.github.io/langgraph/how-tos/node-retries/
How to return state before hitting recursion limit : https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/

### Persistence

Intro : https://langchain-ai.github.io/langgraph/concepts/persistence/
How to add thread-level persistence to your graph : https://langchain-ai.github.io/langgraph/how-tos/persistence/
How to add thread-level persistence to a subgraph : https://langchain-ai.github.io/langgraph/how-tos/subgraph-persistence/
How to add cross-thread persistence to your graph : https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/
How to use Postgres checkpointer for persistence : https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/
How to create a custom checkpointer using Redis : https://langchain-ai.github.io/langgraph/how-tos/persistence_redis/
See the below guides for how-to add persistence to your workflow using the Functional API: https://langchain-ai.github.io/langgraph/concepts/functional_api/
How to add thread-level persistence (functional API) : https://langchain-ai.github.io/langgraph/how-tos/persistence-functional/
How to add cross-thread persistence (functional API) : https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence-functional/

### Memory

Intro : https://langchain-ai.github.io/langgraph/concepts/memory/
How to manage conversation history : https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/
How to delete messages : https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/
How to add summary of the conversation history : https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/
How to add cross-thread persistence to your graph : https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/
How to add semantic search to your agent's memory : https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/

### Human-in-the-loop

Intro : https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/
How to wait for user input using interrupt : https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/
How to Review Tool Calls : https://langchain-ai.github.io/langgraph/how-tos/#setup
How to add breakpoints : https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/
How to edit graph state : https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/
How to add dynamic breakpoints with NodeInterrupt : https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/dynamic_breakpoints/
How to wait for user input (Functional API) : https://langchain-ai.github.io/langgraph/how-tos/wait-user-input-functional/
How to review tool calls (Functional API) : https://langchain-ai.github.io/langgraph/how-tos/review-tool-calls-functional/

### Time Travel

Intro : https://langchain-ai.github.io/langgraph/concepts/time-travel/
How to view and update past graph state : https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/

### Streaming

Intro : https://langchain-ai.github.io/langgraph/concepts/streaming/
How to stream : https://langchain-ai.github.io/langgraph/how-tos/streaming/
How to stream LLM tokens from your graph : https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/
How to stream LLM tokens from specific nodes : https://langchain-ai.github.io/langgraph/how-tos/streaming-specific-nodes/
How to stream data from within a tool : https://langchain-ai.github.io/langgraph/how-tos/streaming-events-from-within-tools/
How to stream from subgraphs : https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/
How to disable streaming for models that don't support it : https://langchain-ai.github.io/langgraph/how-tos/disable-streaming/

### Tool calling

Intro : https://python.langchain.com/docs/concepts/tool_calling/
How to call tools using ToolNode : https://langchain-ai.github.io/langgraph/how-tos/tool-calling/
How to handle tool calling errors : https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/
How to pass runtime values to tools : https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/
How to pass config to tools : https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/
How to update graph state from tools : https://langchain-ai.github.io/langgraph/how-tos/update-state-from-tools/
How to handle large numbers of tools : https://langchain-ai.github.io/langgraph/how-tos/many-tools/

### Multi-agent

Intro : https://langchain-ai.github.io/langgraph/concepts/multi_agent/
How to implement handoffs between agents : https://langchain-ai.github.io/langgraph/how-tos/agent-handoffs/
How to build a multi-agent network : https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network/
How to add multi-turn conversation in a multi-agent application : https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/
How to build a multi-agent network (functional API) : https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network-functional/
How to add multi-turn conversation in a multi-agent application (functional API) : https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo-functional/

### State Management

How to use Pydantic model as graph state : https://langchain-ai.github.io/langgraph/how-tos/state-model/
How to define input/output schema for your graph : https://langchain-ai.github.io/langgraph/how-tos/input_output_schema/
How to pass private state between nodes : https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/

### Others

How to run a graph asynchronously : https://langchain-ai.github.io/langgraph/how-tos/async/
How to force tool-calling agent to structure output : https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/

Graphs API Reference : https://langchain-ai.github.io/langgraph/reference/graphs/

# Stack

## Memory

app/db/db.py will be a centralised session manager for Sqlite

This will be used to for literally everything i.e in place of redis, postgres, etc etc and for all the memory items in the planned hierarchy.Now we will build seperate handlers on top fo rthis based on the memory hierarchy and these handlers will use db.pyLater we will be replacing the db.py needed with Redis, Postgres, etc and replace the dependency in the handler.

## Agent Base Class

app/agnet/agent.py will be a base class for the agent. This class will abstract the Langgraph gent functionality and will be exposed to build sophesticated functionalities planned on top of it. This class basically will sit on Top of LLM and make the LLM a basic agent.

So, This will implement the default agent and the agent implemented here will have all the # Default Characteristics of every Agent

1. Every Agent should have chain of thoughts reasoning
2. Every Agen should follow ReAct (Reasoning + Act)
3. Every Agent should posses a feedback loop and contiunously learn from feedback and memory
4. Stateful -> Strictly rememeber the previous interations
5. Every Agents should Divide large problems to small sub tasks

By Default it will follow this pattern Planner - Executor - Evaulator Patterns : One agent plans, other agent executes and otehr agent validtes the output. Hence this will be its loop Percieve -> Plan -> Act -> Learn -> Repeat


### Plan:

Here we start with iteratively asking the LLM to plan the next step to solve the given prompt. We will be asking the LLm to provide just one next step. and append that step to teh next iteration prompt. In this was we will have a list of all the steps to tackle this problem (Query).

Liek once a Plan() object is geenrated and added to the plan list. We need to pass the query and that particualr step to the LLM and get reasoning for this particualr step. Thei reasoning can be an aswer for the plan if the plan step has a question , or a task if the plan is describing to do something, etc

So There should be a reasoning queue so that as soon as a plan is added via add_step methos, that will add the decription to the the queue. Now The Reasoning loop picks that up and get a structured output about the reasoning i.e solving the plan and add that to the reason list.

Both of these should run in parallel. So that as soon as a plan step is added, there should also be reasoning done in parallel.

At last the index of each plan in PlanandReason object will match the index of each reason. 

### act

So now once the _plan and reason has doen its job it will just pass the plan and reason objec tot _act

Now _act will act based on it. as of now Just asnwer the user based on the given planandreason data.

So in the act we will pass on all the planning and reasoning data to the LLM and properly get the output as an aswer tot he query. 

So as of nwo we need to make the _act to properly understadn the query, plan and the reason and posperly format the response in Markdown. Teh resposne should not miss any thing that is mentioned in the planandreason