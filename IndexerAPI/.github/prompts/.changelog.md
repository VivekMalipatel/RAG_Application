We are in the processing of refactoring and upgrading this Indexer API. 

Majot Changes outline:
1. Remove dependeecy of SQL alchmey sqlite DB adn FAISS, and repalce FAISS with Neo4j. For Neo4j the ingestion pipeline changes based on the incomign ingest file type. Liek we need to add some extra steps like extracting entities and relationships, etc. I will give you more information on it later. 
2. The search will just have one api that is to execute cypher queries.

our task for now is to just start from a point.

That will be ingest.py for now.


Here we have three ingest APIs, We need to properly rewritye them. 


CHanges:
1. The three APIs will still remain the same but there will be properl Request and reposne model for each api.

For /file

class FileIngestRequest(BaseModel):
    user_id: str
    org_id: str
    s3_url: str
    source: str
    metadata: dict

for /url

class FileIngestRequest(BaseModel):
    user_id: str
    org_id: str
    url: str
    source: str
    metadata: dict

for /raw-text

class FileIngestRequest(BaseModel):
    user_id: str
    org_id: str
    text: str
    source: str
    metadata: dict

then we will enqueue this message to rmq

Fo this we wil just have once method to enqueue the messagein rmq hanlder. with this base model message. 


File processing pipeline

1. Determine the file type unstructured, structured, direct
2. If Unstructured:
    1. Convert to pdf with unoserver
    2. Covert that pdf to images (each page is an image) not for each image,
        1. extract text with mark it down
        2. generate text description
        3. Combine the image, text description and image of the page in the openai mesaages format
                    [{
                    "role": "user",
                        "content": [
                        {"type": "image_url", "image_url": {"url": image base64}},
                        {"type": "text", "text": "<Description>, Extracted text from page <extracted Text>"},
                        ],
                    }]
            and embed it 
        4. upload the page image to s3 (S3_BUCKET_NAME/metadata/source/file_data)
        5. Extract Entities and Relationships
            1.  The below is the process that I have used for some other project that indexes offcial documents. But here we need to geenralise the prompt for all the general and personal usecases
            
                """
                class EntitySchema(BaseModel):
                        id: str
                        text: str 
                        entity_type: str
                        entity_profile: str

                    class RelationSchema(BaseModel):
                        source: str 
                        target: str 
                        relation_type: str
                        confidence: float
                        relation_profile: str 

                    class EntityRelationSchema(BaseModel):
                        entities: List[EntitySchema]
                        relationships: List[RelationSchema]
                
                async def _extract_entities_relationships(self, text: str = "", image_b64: str = "") -> Dict[str, Any]:
                        try:
                            extraction_prompt = """Extract comprehensive entities, relationships, and document metadata from the given content for official and organizational document analysis.

                            CRITICAL EXTRACTION REQUIREMENTS:
                            1. Extract ALL identifiable information with high precision for organizational use
                            2. Create entity IDs using lowercase with underscores: "John Smith" -> "john_smith"
                            3. Extract relationships with confidence scores (0.0-1.0) and organizational context
                            4. Provide detailed entity profiles with roles, titles, and organizational standing
                            5. Handle coreference resolution (he/she -> actual name)
                            6. Extract document structure and organizational elements
                            7. For images, extract visual entities, charts, signatures, logos, and relationships

                            COMPREHENSIVE ENTITY TYPES:
                            - PERSON: Individuals, employees, executives, managers, consultants, stakeholders, customers
                            - ORGANIZATION: Companies, departments, divisions, agencies, institutions, vendors, partners
                            - LOCATION: Offices, facilities, regions, countries, addresses, service areas, sites
                            - DOCUMENT: Reports, policies, procedures, agreements, proposals, specifications, manuals
                            - IDENTIFIER: Employee IDs, project codes, reference numbers, account numbers, serial numbers
                            - BUSINESS_CONCEPT: Strategies, methodologies, frameworks, standards, best practices
                            - FINANCIAL: Budgets, costs, revenues, expenses, investments, allocations, pricing
                            - DATE_TIME: Deadlines, milestones, schedules, periods, durations, timelines
                            - REQUIREMENT: Objectives, goals, specifications, criteria, standards, deliverables
                            - POSITION_TITLE: Job titles, roles, responsibilities, organizational levels, functions
                            - CONTACT_INFO: Phone numbers, emails, addresses, communication channels
                            - ASSET: Equipment, technology, resources, tools, systems, infrastructure
                            - PROCESS: Workflows, procedures, methodologies, operations, activities
                            - CLASSIFICATION: Categories, types, levels, priorities, statuses, classifications
                            - PRODUCT_SERVICE: Offerings, solutions, applications, systems, platforms
                            - METRIC: KPIs, measurements, benchmarks, targets, performance indicators

                            COMPREHENSIVE RELATIONSHIP TYPES:
                            - WORKS_FOR: Employment or service relationship
                            - MANAGES: Management or supervisory relationship
                            - REPORTS_TO: Hierarchical reporting structure
                            - COLLABORATES_WITH: Working partnership or cooperation
                            - CONTRACTED_WITH: Business or service agreements
                            - LOCATED_AT: Physical or organizational location
                            - VALID_FROM/UNTIL: Temporal validity and duration
                            - RESPONSIBLE_FOR: Accountability and ownership
                            - AUTHORIZED_BY: Approval or authorization chain
                            - REFERENCES: Citations, cross-references, dependencies
                            - SUPERSEDES: Version control and document evolution
                            - CONTAINS: Document structure and inclusions
                            - PARTICIPATES_IN: Involvement or engagement
                            - FUNDS: Financial relationships and allocations
                            - USES: Tool, system, or resource utilization
                            - PRODUCES: Output or deliverable creation
                            - DEPENDS_ON: Dependencies and prerequisites
                            - ASSIGNED_TO: Task or responsibility assignment
                            - APPROVES: Approval or sign-off processes

                            DOCUMENT STRUCTURE EXTRACTION:
                            - Document title, subtitle, and purpose statement
                            - Section headings, subheadings, and organization
                            - Document type, category, and classification
                            - Version numbers, revision history, and dates
                            - Appendices, exhibits, and attachment references
                            - Table of contents and navigation elements
                            - Page numbers, headers, and footers
                            - Signature blocks, approval sections, and stamps
                            - Watermarks, logos, and branding elements

                            TABULAR DATA EXTRACTION:
                            - Extract all structured data from tables and charts
                            - Identify headers, columns, rows, and data relationships
                            - Capture numerical data, statistics, and measurements
                            - Extract schedules, calendars, and timeline information
                            - Identify budgets, financial data, and cost breakdowns
                            - Process organizational charts and hierarchy diagrams
                            - Extract performance metrics and dashboard data

                            ORGANIZATIONAL DOCUMENT EXTRACTION:
                            - Mission, vision, and strategic objectives
                            - Policies, procedures, and standard operating procedures
                            - Organizational structure and reporting lines
                            - Project plans, timelines, and resource allocations
                            - Performance metrics, goals, and success criteria
                            - Risk assessments and mitigation strategies
                            - Training materials and knowledge base content
                            - Meeting minutes, decisions, and action items
                            - Communication protocols and escalation procedures
                            - Quality standards and certification requirements

                            The goal is to provide comprehensive document intelligence with entities and relationships extraction for any official or organizational context, capturing every significant detail relevant for business operations, compliance, analysis, decision-making, and knowledge management.
                            """

                            if text and image_b64:
                                user_prompt = f"{extraction_prompt}\n\nExtract entities and relationships from both the text content and the image.\n\nTEXT CONTENT:\n{text}\n\nIMAGE: [Image provided - analyze both text and visual content]"
                            elif text:
                                user_prompt = f"{extraction_prompt}\n\nExtract entities and relationships from the following text.\n\nTEXT CONTENT:\n{text}"
                            elif image_b64:
                                user_prompt = f"{extraction_prompt}\n\nExtract entities and relationships from the image content. Analyze visual elements, text in the image, diagrams, charts, etc."
                            else:
                                return {"entities": [], "relationships": []}

                            if image_b64:
                                messages = [
                                    {
                                        "role": "user", 
                                        "content": [
                                            {"type": "text", "text": user_prompt},
                                            {
                                                "type": "image_url",
                                                "image_url": {
                                                    "url": "data:image/jpeg;base64," + image_b64,
                                                }
                                            },
                                            {"type": "text", "text":Extracted text},
                                        ]
                                    }
                                ]
                            else:
                                messages = [{"role": "user", "content": user_prompt}]

                            response = await self.openai_client.beta.chat.completions.parse(
                                model=self.qwen_model_name,
                                messages=messages,
                                response_format=EntityRelationSchema,
                            )
                            
                            if response.choices[0].message.parsed:
                                parsed_result = response.choices[0].message.parsed
                                entities = [entity.dict() for entity in parsed_result.entities]
                                relationships = [rel.dict() for rel in parsed_result.relationships]
                                
                                for entity in entities:
                                    entity["id"] = entity["id"].lower().replace(" ", "_").replace("-", "_")
                                
                                for rel in relationships:
                                    rel["source"] = rel["source"].lower().replace(" ", "_").replace("-", "_")
                                    rel["target"] = rel["target"].lower().replace(" ", "_").replace("-", "_")
                                
                                return {"entities": entities, "relationships": relationships}
                            else:
                                logger.error("Failed to parse structured entity extraction output")
                                return {"entities": [], "relationships": []}
                            
                        except Exception as e:
                            logger.error(f"Entity extraction failed: {e}")
                            return {"entities": [], "relationships": []}"
                    """
            2. We need to embedding each entitiy and relationship profile text and put it back to the entities ["embedding"] and relationships ["embedding"]
            3. return
        6. Now we need to generate Neo4j proper pamppings for neo4j and push it to neo4j
           
           Here is the mapping schmea:

           [Document Node] -> [Page Node] ----------------------> [Entity]
                                  |                               ^
                                  v                               |
                            [Entity] <-----RelationshipEdge--------

            Document Node schema:
            1. all the feilds in the metadata as a seperate column (whatever the metadata can be)
            2. user_id
            3. org_id
            4. s3_url
            5. source

            Page Node:
            1. Page Number
            2. user_id
            3. org_id
            4. Page Extracted Text
            5. Page Image URL (The one we upload to s3)
            6. embedding

            Entity:
            1. id
            2. text
            3. entity_type
            4. entity_profile
            5. embedding

            Relationship:
            1. source
            2. target
            3. relation_type
            4. relation_profile
            5. embedding

            [Document node] ----[Has Page]----->[Page Node]
            [Page Node] -----[Mentions]---->[Entity]
            [Entity] --------[Relationship]---->[Entity]
        
        7. Ensure there are 3 indexes for three embeddings regsitered in neo4j
        8. Return Success 
    3. Returun Success

3. Is Structured:
   There are the csv, xls,xlsx etc which are in tabular
   1. Read the csv, xls, xlsx with pandas (read all the sheets)
   2. Here each sheet will be a page for us. for each sheet
        1. If Excel file, see if its a proper tabular structre (i.e header columns is there with proper table strcutre)
        2. If yes,
            1. Read the documet with pandas
            2. Describe the pandas dataframe, convert it to text. Take the header and first 20 rows of the dataframe and convert it to markdown text like string and give it to llm to get the summary. For each column get a description based on the data. These will be two seperate LLm calls one for summary, one of gettign the strcutrued oupturts with column name and column profile
            3. Embed column summary, and column profiles
            4. We need to feed this data to neo4j in the same strcutred way like
                assumer

                Coulmns ->  A  B  C
                Row1 ->     x  y  z
                Row2 ->     a  b  c


                The Mapping schema will be like


                                    [Column3 (C)]
                                        ^
                                        |
                [Document Node] -> [Page Node (sheet)] ----> [Coulmn1 (A)]
                                    |
                                    v
                                    [Column2 (B)]
                
                Here are the links

                [Coulmn1 (A)] ---> [x]
                [Coulmn1 (A)] ---> [a]
                [Column2 (B)] ---> [y]
                [Column2 (B)] ---> [b]
                [Column3 (C)] ---> [z]
                [Column3 (C)] ---> [c]

                [x]->[y]->[z]
                [a]->[b]->[c]

                Document Node schema:
                1. all the feilds in the metadata as a seperate column (whatever the metadata can be)
                2. user_id
                3. org_id
                4. s3_url
                5. source

                Page Node (sheet):
                1. Page Number (sheet)
                2. user_id
                3. org_id
                4. Page Summary
                5. Page Image URL (The one we upload to s3)
                6. embedding

                Column Node:
                1. Column Name
                2. Column Profile
                3. Embedding

                Row Noe:
                1. Row Item

                [Document node] ----[Has Page]----->[Page Node]
                [Page Node] -----[MENTIONS]---->[Column]
                [Row Node] --------[RELATES TO]--------[R]


            5. Push the data to neo4j
            6. Ensure there are 2 indexes for three embeddings regsitered in neo4j 
               1. Page Node Index will be same as the page node index in Unstructured (same index space)
               2. Coumn Nodde Index will be same as the Entity index in Unstrcutred (same index space)
        3. If No,
            1. Extract the text from the sheet with markitdown
            2. Break down the text to chunks of <= 8000 words, each page will be each 8000 words. Then we will do the entitiy realtion extract and push them to neo4j as same as how we did for unstructred (except description generation)
4. Is Direct:
    1. Extract the text from the sheet with markitdown. Each page will be each 8000 words
    2. Extract the entities and rekationships 
    3. Embed the text, ER
    4. Push it to the Neo4j


All these utitlty methodslike ER extractiopn and embedding and descritpion generation methods should be in app/core/model/model_handler.py. 