### Context

We are starting to build a new API using Fast API This would be a File Indexer Microservice as part of a RAG system.

scope of this microservice is Take any file(PDF, Image, Video, Audio - all in multiple formats) or RAW Text (JSON, HTML,Markdown) or Link and embed that data and store in vector db and possible generate Knowledge graphs. It also is responsible for updating/storing and maintaining the incoming files's extracted content, metadata, source, etc etc in a SQL database (SQLite as of now but will later upgrade to postgres). Handler classes for qdrant and Neo4j is out of scope of this project. This API Takes the file and gives response with embeddings and knowledge graph data (possibly). This will be deployed in docker.

SO now start prepping the folder and folder structure and infra for Fast API and this requirements. The below plan is just initial plan but is still prone to develop a lot

For your context:
/reference_code folder has the code that has been pulled from previous prototype demo, that has the file processing pipeline. But we are totally updgrading that pipeline. 
/pre-tests has the test files that have the testst done on differetn libraries and frameworks on the approach we will be following now. 
The Screenshot attached has the planned flow for this project. 

So you can take the /reference_code with a pinch of salt and /pre-tests are the core concepts that will be scaling and implementing properly with all file type. 

### TASK

Now start building the basics starters for the project and then we will continue with building this microservice. 

### Plan and Flow

Here is the basic Flow and plan :

ðŸ“¥ Input Sources

The pipeline accepts the following types of inputs:
	â€¢	Document Files:
	â€¢	PDFs, Word Docs, Excel Sheets
	â€¢	CSV, JPEG, MP4, etc.
	â€¢	Raw Text Files
	â€¢	Web Links

â¸»

ðŸ”„ File Indexer API

All incoming files and links are processed through the File Indexer API. This API is responsible for:
	â€¢	Receiving files or links
	â€¢	Enqueuing them for processing
	â€¢	Storing associated metadata

â¸»

ðŸ“¦ Queue and Temporary Storage

After being received by the API:
	â€¢	Files are placed in a processing queue
	â€¢	Raw text or webhook data is stored with metadata in the queue
	â€¢	Files are uploaded to temporary object storage (e.g., S3 or MinIO)

â¸»

ðŸ§  Input Type Detection

The Input Type Detector determines the nature of the input and routes it appropriately:
	â€¢	Document Files
	â€¢	Raw Text
	â€¢	Web Links
	â€¢	Audio Files
	â€¢	Video Files

â¸»

ðŸ“„ Processing Document Files
	1.	Convert to Images: Each page or element is transformed into image format.
	2.	Extract Text: Text is extracted from both the original document and the image representation.
	3.	Captioned Images: Images are captioned using vision models.
	4.	Multimodal Embeddings: Both text and image data are passed to a multimodal embedding model.
	5.	Vector Database: Resulting embeddings are stored in a vector DB for retrieval.

â¸»

âœï¸ Processing Raw Text
	1.	Markdown Conversion: Raw text is converted to markdown.
	2.	Extract Text: Directly use the text or enhanced markdown for further analysis.
	3.	LLM Processing:
	â€¢	Ollama LLM is used to analyze or enrich the markdown content.

â¸»

ðŸŒ Processing Web Links
	â€¢	Check if YouTube URL:
	â€¢	Yes:
	â€¢	Use Mark it Down â†’ Extract HTML Content â†’ Use Ollama VLM
	â€¢	No:
	â€¢	Browse Page â†’ Extract HTML Content â†’ Use Ollama VLM

â¸»

ðŸ”Š Processing Audio Files
	â€¢	Decision node: Speech?
	â€¢	If Yes:
	â€¢	Use Mark it Down â†’ Extract Transcription
	â€¢	If No:
	â€¢	Yet to plan

â¸»

ðŸŽ¥ Processing Video Files
	â€¢	yet to plan

â¸»

ðŸ—ƒ Metadata Schema

Each item processed stores metadata in the following schema:
	1.	Source â€“ The origin of the file or link
  2.  Data - The actual data (Byte IO in case of a file, JSON String in case of Weblink or RAW text)
	3.	Metadata â€“ Metadata for the data, can be different for different data sources and input types. Like file can have file name, mime type, etc etc. RAW Text can have context, to, from, etc etc
	3.	Indexing Date and Time â€“ Date.Now -> This is just for the versioning purpose that will store the current time and date at which the data has been sent for indexing.

### Yet to be plannned

1. How will the embedded data will reach vector db? For this we are yet to write API for vector DB. So this API will be calling the vector db API to store the embeddings
2. Are we planning to build knowlegde graphs? No plan as of now. But will plan once the basic pipeline is done.
3. Audio and Video Processing

### API Design

openapi: 3.0.3
info:
  title: File Indexer API
  version: 1.2.0
  description: API for ingesting files, raw text, and URLs, with support for checking processing status.

servers:
  - url: https://api.example.com/v1

paths:
  /ingest/file:
    post:
      summary: Upload a file for indexing
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required:
                - file
                - source
              properties:
                file:
                  type: string
                  format: binary
                  description: The file to be processed
                source:
                  type: string
                  description: The source of the file
                metadata:
                  type: string
                  description: JSON string containing metadata about the file
      responses:
        '202':
          description: File accepted for processing
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/IngestResponse'
        '400':
          description: Invalid file format or request

  /ingest/url:
    post:
      summary: Submit a web link for indexing
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UrlIngestRequest'
      responses:
        '202':
          description: URL accepted for processing
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/IngestResponse'
        '400':
          description: Invalid URL or request format

  /ingest/raw-text:
    post:
      summary: Submit raw text for indexing
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RawTextIngestRequest'
      responses:
        '202':
          description: Raw text accepted for processing
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/IngestResponse'
        '400':
          description: Invalid input

  /status/{item_id}:
    get:
      summary: Get processing status of a submitted item
      parameters:
        - name: item_id
          in: path
          required: true
          schema:
            type: string
          description: Unique identifier of the submitted item
      responses:
        '200':
          description: Current status of the item
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/StatusResponse'
        '404':
          description: Submission ID not found

components:
  schemas:
    IngestResponse:
      type: object
      properties:
        id:
          type: string
          description: Unique identifier for tracking the submission
        message:
          type: string
          description: Status message
      required:
        - id
        - message
      
    UrlIngestRequest:
      type: object
      properties:
        url:
          type: string
          format: uri
          description: The URL to be processed
        source:
          type: string
          description: The source of the URL
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata about the URL
      required:
        - url
        - source
        
    RawTextIngestRequest:
      type: object
      properties:
        text:
          type: string
          description: The raw text content to be processed
        source:
          type: string
          description: The source of the text
        metadata:
          type: object
          additionalProperties: true
          description: Additional metadata about the text
      required:
        - text
        - source
        
    StatusResponse:
      type: object
      properties:
        id:
          type: string
          description: The unique identifier of the submission
        status:
          type: string
          enum: [queued, processing, completed, failed]
          description: Current processing status
        message:
          type: string
          description: Additional status details or progress information
        result:
          type: object
          nullable: true
          description: Processing results if completed
      required:
        - id
        - status
        - message

  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key

security:
  - ApiKeyAuth: []

### Current Implementation Plan

1. Lets focus only on Documents with Images and text and focus on Video and audio later. But we will be buidling the temp classes for them too. 
2. 

### How are we doing Emedding and LLM usage? (Model Router API)

I have custom built a reverse engineered Open AI like endpoints API that directly works with Openai python library (for text generation and also structured outputs) and for embedding we will desicde if we directly use the openai python library or should cusomtly do the curl commands.

### Queue Handling

The usage for queue will be:
What ever the request we get we will put that in the queue. As the file will always be coming in byte IO and RAW text weill be coming in JSON string and Web Link will be cmoing in JSON string we can direct put them in the queue (in db). Then we will read them one by one the order of there request and process them.

The request payload will have ,

Source -> From which data source the request is coming from
Data -> The actual data (Byte IO in case of a file, JSON String in case of Weblink or RAW text)
Metadata -> Metadata for the data, can be different for different data sources and input types. Like file can have file name, mime type, etc etc. RAW Text can have context, to, from, etc etc
Indexing Date and time -> Date.Now -> This is just for the versioning purpose that will store the current time and date at which the data has been sent for indexing.
One we recevie a request, we will generate unique id for that queue item and add them to queue. We will be returing this id as a response for status checks from cleints.

### Queue Consumer

in app/services

We need to write queue consumer class.

This will be doing the below things:
It will consume the item from the queue and route it to respective processor and accept processed data from the processors.
There will be only three processors, 
1. FIle Processor
2. Raw text Processor
3. URL processor
We will be creating this processor classes later in app/processors
Every process will be taking the data differetnly but giving out the same kinds of return types. There will be two type of return types from the processors.

1. {data:[{"image": Base64 IMage of the page,
"text": "Extracted Text from that page"}],source:, metadata:, timestamp:}
2. {data:["Markdown Text"],source:, metadata:, timestamp:}

"1" will be if the processor detects some images in the data and "2" will be if the processor detects that the input data will only have text data.
Once this  queue consumer class recevied this retuned data from the processors, it will use the model handler to generate embeddings for these. If the data has [{"image": Base6... then it will pass this data to embed_image else it will pass this data to embed_text
Once it gets the embeddings, it will add the embeddings to the returned payload and send it somewhere (yet to be decided)


### Coding Style and Tech stack

1. It should be completelely modular, Object oriented, well logged
2. No Icons/emoji's in the code or logs
3. As of now we will be sotrng the queue and databse in the same SQlite Db but later upgrading to redis and postgres. So the coding style should be in such a way that with minimal changes we should be able to upgrade.
4. For object storage we will not yet use S3, but use soem temp alternative like how we are using sqlite for postgres aternative but later will be replacing.
5. No Comments or class/methods descriptions should be written.